{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "print(\"\\n\".join(timm.list_models('vi*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e45583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsalan/miniconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Dummy Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import SwinModel, SwinConfig\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "\n",
    "# Dummy dataset loader (replace with ML-JET loader)\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, size=1000):\n",
    "        self.data = torch.rand(size, 1, 32, 32)\n",
    "        self.labels_energy = torch.randint(0, 2, (size, 1)).float()\n",
    "        self.labels_alpha = torch.randint(0, 3, (size,))\n",
    "        self.labels_q0 = torch.randint(0, 4, (size,))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], {\n",
    "            'energy_loss_output': self.labels_energy[idx],\n",
    "            'alpha_output': self.labels_alpha[idx],\n",
    "            'q0_output': self.labels_q0[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ad7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "\n",
    "class ViTTinyMultiHeadClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1) Build a ViT that takes 1√ó32√ó32 inputs directly:\n",
    "        #    - img_size=32, patch_size=4 ‚Üí (32/4=8)^2 = 64 patches\n",
    "        #    - embed_dim small for speed, e.g. 192\n",
    "        #    - depth=4 layers, num_heads=3 (must divide 192)\n",
    "        self.backbone = VisionTransformer(\n",
    "            img_size=32,\n",
    "            patch_size=4,\n",
    "            in_chans=1,\n",
    "            embed_dim=192,\n",
    "            depth=4,\n",
    "            num_heads=3,\n",
    "            mlp_ratio=4.0,\n",
    "            qkv_bias=True,\n",
    "            drop_rate=0.0,\n",
    "            attn_drop_rate=0.0,\n",
    "            drop_path_rate=0.1,\n",
    "            norm_layer=nn.LayerNorm,\n",
    "            num_classes=0,        # returns features\n",
    "        )\n",
    "\n",
    "        # 2) Feature dimension from ViT‚Äôs output:\n",
    "        self.feature_dim = self.backbone.embed_dim  # 192\n",
    "\n",
    "        # 3) Multi‚Äëhead classification layers:\n",
    "        self.energy_head = nn.Linear(self.feature_dim, 1)\n",
    "        self.alpha_head  = nn.Linear(self.feature_dim, 3)\n",
    "        self.q0_head     = nn.Linear(self.feature_dim, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,1,32,32)\n",
    "        feats = self.backbone(x)    # ‚Üí (B, feature_dim)\n",
    "        return {\n",
    "            'energy_loss_output': self.energy_head(feats),\n",
    "            'alpha_output':       self.alpha_head(feats),\n",
    "            'q0_output':          self.q0_head(feats)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781e6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Loss Computation\n",
    "\n",
    "def compute_loss(outputs, targets):\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    loss_energy = bce(outputs['energy_loss_output'], targets['energy_loss_output'])\n",
    "    loss_alpha = ce(outputs['alpha_output'], targets['alpha_output'])\n",
    "    loss_q0 = ce(outputs['q0_output'], targets['q0_output'])\n",
    "    return loss_energy + loss_alpha + loss_q0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ef3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Training Loop Function\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = {k: v.to(device) for k, v in y.items()}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = compute_loss(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0c1e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.3179\n",
      "Epoch 2, Loss: 3.2251\n",
      "Epoch 3, Loss: 3.1911\n",
      "Epoch 4, Loss: 3.1922\n",
      "Epoch 5, Loss: 3.2123\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Main Training Script\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ViTTinyMultiHeadClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "train_loader = DataLoader(DummyDataset(), batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(5):\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# point to the parent directory\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from models.model import create_model\n",
    "class ViTParamClassifier(nn.Module):\n",
    "    def __init__(self, vit_name='vit_base_patch16_224', pretrained=True, num_alpha=3, num_q0=4):\n",
    "        super().__init__()\n",
    "        # Load a ViT without its default head\n",
    "        self.vit = create_model(vit_name, pretrained=pretrained, num_classes=0)\n",
    "        embed_dim = self.vit.num_features  # e.g. 768\n",
    "\n",
    "        # Single binary head for Energy‚ÄëLoss Module\n",
    "        self.energy_head = nn.Linear(embed_dim, 1)\n",
    "\n",
    "        # Categorical heads for alpha_s and Q0\n",
    "        self.alpha_head  = nn.Linear(embed_dim, num_alpha)\n",
    "        self.q0_head     = nn.Linear(embed_dim, num_q0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, 1, 32, 32)  ‚Üí expand to 3 channels & resize if needed\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.repeat(1,3,1,1)\n",
    "        x = nn.functional.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "\n",
    "        features = self.vit(x)  # ‚Üí (B, embed_dim)\n",
    "        return {\n",
    "            'energy': self.energy_head(features).squeeze(1),        # (B,)\n",
    "            'alpha' : self.alpha_head(features),                    # (B,3)\n",
    "            'q0'    : self.q0_head(features)                        # (B,4)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ea3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example losses\n",
    "bce   = nn.BCEWithLogitsLoss()\n",
    "ce    = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(start_epoch, cfg.epochs):\n",
    "    model.train()\n",
    "    for imgs, (y_energy, y_alpha, y_q0) in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        out = model(imgs)\n",
    "        loss = (\n",
    "            bce(out['energy'], y_energy.to(device).float()) +\n",
    "            ce(out['alpha'],  y_alpha.to(device)) +\n",
    "            ce(out['q0'],     y_q0.to(device))\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ‚Ä¶ validation, logging, early‚Äëstop checks ‚Ä¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c373b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç All ViT models:\n",
      "  - vit_base_mci_224\n",
      "  - vit_base_patch8_224\n",
      "  - vit_base_patch14_dinov2\n",
      "  - vit_base_patch14_reg4_dinov2\n",
      "  - vit_base_patch16_18x2_224\n",
      "  - vit_base_patch16_224\n",
      "  - vit_base_patch16_224_miil\n",
      "  - vit_base_patch16_384\n",
      "  - vit_base_patch16_clip_224\n",
      "  - vit_base_patch16_clip_384\n",
      "  - vit_base_patch16_clip_quickgelu_224\n",
      "  - vit_base_patch16_gap_224\n",
      "  - vit_base_patch16_plus_240\n",
      "  - vit_base_patch16_plus_clip_240\n",
      "  - vit_base_patch16_reg4_gap_256\n",
      "  - vit_base_patch16_rope_reg1_gap_256\n",
      "  - vit_base_patch16_rpn_224\n",
      "  - vit_base_patch16_siglip_224\n",
      "  - vit_base_patch16_siglip_256\n",
      "  - vit_base_patch16_siglip_384\n",
      "  - vit_base_patch16_siglip_512\n",
      "  - vit_base_patch16_siglip_gap_224\n",
      "  - vit_base_patch16_siglip_gap_256\n",
      "  - vit_base_patch16_siglip_gap_384\n",
      "  - vit_base_patch16_siglip_gap_512\n",
      "  - vit_base_patch16_xp_224\n",
      "  - vit_base_patch32_224\n",
      "  - vit_base_patch32_384\n",
      "  - vit_base_patch32_clip_224\n",
      "  - vit_base_patch32_clip_256\n",
      "  - vit_base_patch32_clip_384\n",
      "  - vit_base_patch32_clip_448\n",
      "  - vit_base_patch32_clip_quickgelu_224\n",
      "  - vit_base_patch32_plus_256\n",
      "  - vit_base_patch32_siglip_256\n",
      "  - vit_base_patch32_siglip_gap_256\n",
      "  - vit_base_r26_s32_224\n",
      "  - vit_base_r50_s16_224\n",
      "  - vit_base_r50_s16_384\n",
      "  - vit_base_resnet26d_224\n",
      "  - vit_base_resnet50d_224\n",
      "  - vit_betwixt_patch16_gap_256\n",
      "  - vit_betwixt_patch16_reg1_gap_256\n",
      "  - vit_betwixt_patch16_reg4_gap_256\n",
      "  - vit_betwixt_patch16_reg4_gap_384\n",
      "  - vit_betwixt_patch16_rope_reg4_gap_256\n",
      "  - vit_betwixt_patch32_clip_224\n",
      "  - vit_giant_patch14_224\n",
      "  - vit_giant_patch14_clip_224\n",
      "  - vit_giant_patch14_dinov2\n",
      "  - vit_giant_patch14_reg4_dinov2\n",
      "  - vit_giant_patch16_gap_224\n",
      "  - vit_giantopt_patch16_siglip_256\n",
      "  - vit_giantopt_patch16_siglip_384\n",
      "  - vit_giantopt_patch16_siglip_gap_256\n",
      "  - vit_giantopt_patch16_siglip_gap_384\n",
      "  - vit_gigantic_patch14_224\n",
      "  - vit_gigantic_patch14_clip_224\n",
      "  - vit_gigantic_patch14_clip_quickgelu_224\n",
      "  - vit_huge_patch14_224\n",
      "  - vit_huge_patch14_clip_224\n",
      "  - vit_huge_patch14_clip_336\n",
      "  - vit_huge_patch14_clip_378\n",
      "  - vit_huge_patch14_clip_quickgelu_224\n",
      "  - vit_huge_patch14_clip_quickgelu_378\n",
      "  - vit_huge_patch14_gap_224\n",
      "  - vit_huge_patch14_xp_224\n",
      "  - vit_huge_patch16_gap_448\n",
      "  - vit_intern300m_patch14_448\n",
      "  - vit_large_patch14_224\n",
      "  - vit_large_patch14_clip_224\n",
      "  - vit_large_patch14_clip_336\n",
      "  - vit_large_patch14_clip_quickgelu_224\n",
      "  - vit_large_patch14_clip_quickgelu_336\n",
      "  - vit_large_patch14_dinov2\n",
      "  - vit_large_patch14_reg4_dinov2\n",
      "  - vit_large_patch14_xp_224\n",
      "  - vit_large_patch16_224\n",
      "  - vit_large_patch16_384\n",
      "  - vit_large_patch16_siglip_256\n",
      "  - vit_large_patch16_siglip_384\n",
      "  - vit_large_patch16_siglip_512\n",
      "  - vit_large_patch16_siglip_gap_256\n",
      "  - vit_large_patch16_siglip_gap_384\n",
      "  - vit_large_patch16_siglip_gap_512\n",
      "  - vit_large_patch32_224\n",
      "  - vit_large_patch32_384\n",
      "  - vit_large_r50_s32_224\n",
      "  - vit_large_r50_s32_384\n",
      "  - vit_little_patch16_reg1_gap_256\n",
      "  - vit_little_patch16_reg4_gap_256\n",
      "  - vit_medium_patch16_clip_224\n",
      "  - vit_medium_patch16_gap_240\n",
      "  - vit_medium_patch16_gap_256\n",
      "  - vit_medium_patch16_gap_384\n",
      "  - vit_medium_patch16_reg1_gap_256\n",
      "  - vit_medium_patch16_reg4_gap_256\n",
      "  - vit_medium_patch16_rope_reg1_gap_256\n",
      "  - vit_medium_patch32_clip_224\n",
      "  - vit_mediumd_patch16_reg4_gap_256\n",
      "  - vit_mediumd_patch16_reg4_gap_384\n",
      "  - vit_mediumd_patch16_rope_reg1_gap_256\n",
      "  - vit_pwee_patch16_reg1_gap_256\n",
      "  - vit_relpos_base_patch16_224\n",
      "  - vit_relpos_base_patch16_cls_224\n",
      "  - vit_relpos_base_patch16_clsgap_224\n",
      "  - vit_relpos_base_patch16_plus_240\n",
      "  - vit_relpos_base_patch16_rpn_224\n",
      "  - vit_relpos_base_patch32_plus_rpn_256\n",
      "  - vit_relpos_medium_patch16_224\n",
      "  - vit_relpos_medium_patch16_cls_224\n",
      "  - vit_relpos_medium_patch16_rpn_224\n",
      "  - vit_relpos_small_patch16_224\n",
      "  - vit_relpos_small_patch16_rpn_224\n",
      "  - vit_small_patch8_224\n",
      "  - vit_small_patch14_dinov2\n",
      "  - vit_small_patch14_reg4_dinov2\n",
      "  - vit_small_patch16_18x2_224\n",
      "  - vit_small_patch16_36x1_224\n",
      "  - vit_small_patch16_224\n",
      "  - vit_small_patch16_384\n",
      "  - vit_small_patch32_224\n",
      "  - vit_small_patch32_384\n",
      "  - vit_small_r26_s32_224\n",
      "  - vit_small_r26_s32_384\n",
      "  - vit_small_resnet26d_224\n",
      "  - vit_small_resnet50d_s16_224\n",
      "  - vit_so150m2_patch16_reg1_gap_256\n",
      "  - vit_so150m2_patch16_reg1_gap_384\n",
      "  - vit_so150m2_patch16_reg1_gap_448\n",
      "  - vit_so150m_patch16_reg4_gap_256\n",
      "  - vit_so150m_patch16_reg4_gap_384\n",
      "  - vit_so150m_patch16_reg4_map_256\n",
      "  - vit_so400m_patch14_siglip_224\n",
      "  - vit_so400m_patch14_siglip_378\n",
      "  - vit_so400m_patch14_siglip_384\n",
      "  - vit_so400m_patch14_siglip_gap_224\n",
      "  - vit_so400m_patch14_siglip_gap_378\n",
      "  - vit_so400m_patch14_siglip_gap_384\n",
      "  - vit_so400m_patch14_siglip_gap_448\n",
      "  - vit_so400m_patch14_siglip_gap_896\n",
      "  - vit_so400m_patch16_siglip_256\n",
      "  - vit_so400m_patch16_siglip_384\n",
      "  - vit_so400m_patch16_siglip_512\n",
      "  - vit_so400m_patch16_siglip_gap_256\n",
      "  - vit_so400m_patch16_siglip_gap_384\n",
      "  - vit_so400m_patch16_siglip_gap_512\n",
      "  - vit_srelpos_medium_patch16_224\n",
      "  - vit_srelpos_small_patch16_224\n",
      "  - vit_tiny_patch16_224\n",
      "  - vit_tiny_patch16_384\n",
      "  - vit_tiny_r_s16_p8_224\n",
      "  - vit_tiny_r_s16_p8_384\n",
      "  - vit_wee_patch16_reg1_gap_256\n",
      "  - vit_xsmall_patch16_clip_224\n",
      "  - vitamin_base_224\n",
      "  - vitamin_large2_224\n",
      "  - vitamin_large2_256\n",
      "  - vitamin_large2_336\n",
      "  - vitamin_large2_384\n",
      "  - vitamin_large_224\n",
      "  - vitamin_large_256\n",
      "  - vitamin_large_336\n",
      "  - vitamin_large_384\n",
      "  - vitamin_small_224\n",
      "  - vitamin_xlarge_256\n",
      "  - vitamin_xlarge_336\n",
      "  - vitamin_xlarge_384\n",
      "\n",
      "‚úÖ Pretrained ConvNeXt models:\n",
      "  - vit_base_mci_224.apple_mclip\n",
      "  - vit_base_mci_224.apple_mclip_lt\n",
      "  - vit_base_patch8_224.augreg2_in21k_ft_in1k\n",
      "  - vit_base_patch8_224.augreg_in21k\n",
      "  - vit_base_patch8_224.augreg_in21k_ft_in1k\n",
      "  - vit_base_patch8_224.dino\n",
      "  - vit_base_patch14_dinov2.lvd142m\n",
      "  - vit_base_patch14_reg4_dinov2.lvd142m\n",
      "  - vit_base_patch16_224.augreg2_in21k_ft_in1k\n",
      "  - vit_base_patch16_224.augreg_in1k\n",
      "  - vit_base_patch16_224.augreg_in21k\n",
      "  - vit_base_patch16_224.augreg_in21k_ft_in1k\n",
      "  - vit_base_patch16_224.dino\n",
      "  - vit_base_patch16_224.mae\n",
      "  - vit_base_patch16_224.orig_in21k\n",
      "  - vit_base_patch16_224.orig_in21k_ft_in1k\n",
      "  - vit_base_patch16_224.sam_in1k\n",
      "  - vit_base_patch16_224_miil.in21k\n",
      "  - vit_base_patch16_224_miil.in21k_ft_in1k\n",
      "  - vit_base_patch16_384.augreg_in1k\n",
      "  - vit_base_patch16_384.augreg_in21k_ft_in1k\n",
      "  - vit_base_patch16_384.orig_in21k_ft_in1k\n",
      "  - vit_base_patch16_clip_224.datacompxl\n",
      "  - vit_base_patch16_clip_224.dfn2b\n",
      "  - vit_base_patch16_clip_224.laion2b\n",
      "  - vit_base_patch16_clip_224.laion2b_ft_in1k\n",
      "  - vit_base_patch16_clip_224.laion2b_ft_in12k\n",
      "  - vit_base_patch16_clip_224.laion2b_ft_in12k_in1k\n",
      "  - vit_base_patch16_clip_224.laion400m_e32\n",
      "  - vit_base_patch16_clip_224.metaclip_2pt5b\n",
      "  - vit_base_patch16_clip_224.metaclip_400m\n",
      "  - vit_base_patch16_clip_224.openai\n",
      "  - vit_base_patch16_clip_224.openai_ft_in1k\n",
      "  - vit_base_patch16_clip_224.openai_ft_in12k\n",
      "  - vit_base_patch16_clip_224.openai_ft_in12k_in1k\n",
      "  - vit_base_patch16_clip_384.laion2b_ft_in1k\n",
      "  - vit_base_patch16_clip_384.laion2b_ft_in12k_in1k\n",
      "  - vit_base_patch16_clip_384.openai_ft_in1k\n",
      "  - vit_base_patch16_clip_384.openai_ft_in12k_in1k\n",
      "  - vit_base_patch16_clip_quickgelu_224.metaclip_2pt5b\n",
      "  - vit_base_patch16_clip_quickgelu_224.metaclip_400m\n",
      "  - vit_base_patch16_clip_quickgelu_224.openai\n",
      "  - vit_base_patch16_plus_clip_240.laion400m_e32\n",
      "  - vit_base_patch16_rope_reg1_gap_256.sbb_in1k\n",
      "  - vit_base_patch16_rpn_224.sw_in1k\n",
      "  - vit_base_patch16_siglip_224.v2_webli\n",
      "  - vit_base_patch16_siglip_224.webli\n",
      "  - vit_base_patch16_siglip_256.v2_webli\n",
      "  - vit_base_patch16_siglip_256.webli\n",
      "  - vit_base_patch16_siglip_256.webli_i18n\n",
      "  - vit_base_patch16_siglip_384.v2_webli\n",
      "  - vit_base_patch16_siglip_384.webli\n",
      "  - vit_base_patch16_siglip_512.v2_webli\n",
      "  - vit_base_patch16_siglip_512.webli\n",
      "  - vit_base_patch16_siglip_gap_224.v2_webli\n",
      "  - vit_base_patch16_siglip_gap_224.webli\n",
      "  - vit_base_patch16_siglip_gap_256.v2_webli\n",
      "  - vit_base_patch16_siglip_gap_256.webli\n",
      "  - vit_base_patch16_siglip_gap_256.webli_i18n\n",
      "  - vit_base_patch16_siglip_gap_384.v2_webli\n",
      "  - vit_base_patch16_siglip_gap_384.webli\n",
      "  - vit_base_patch16_siglip_gap_512.v2_webli\n",
      "  - vit_base_patch16_siglip_gap_512.webli\n",
      "  - vit_base_patch32_224.augreg_in1k\n",
      "  - vit_base_patch32_224.augreg_in21k\n",
      "  - vit_base_patch32_224.augreg_in21k_ft_in1k\n",
      "  - vit_base_patch32_224.orig_in21k\n",
      "  - vit_base_patch32_224.sam_in1k\n",
      "  - vit_base_patch32_384.augreg_in1k\n",
      "  - vit_base_patch32_384.augreg_in21k_ft_in1k\n",
      "  - vit_base_patch32_clip_224.datacompxl\n",
      "  - vit_base_patch32_clip_224.laion2b\n",
      "  - vit_base_patch32_clip_224.laion2b_ft_in1k\n",
      "  - vit_base_patch32_clip_224.laion2b_ft_in12k_in1k\n",
      "  - vit_base_patch32_clip_224.laion400m_e32\n",
      "  - vit_base_patch32_clip_224.metaclip_2pt5b\n",
      "  - vit_base_patch32_clip_224.metaclip_400m\n",
      "  - vit_base_patch32_clip_224.openai\n",
      "  - vit_base_patch32_clip_224.openai_ft_in1k\n",
      "  - vit_base_patch32_clip_256.datacompxl\n",
      "  - vit_base_patch32_clip_384.laion2b_ft_in12k_in1k\n",
      "  - vit_base_patch32_clip_384.openai_ft_in12k_in1k\n",
      "  - vit_base_patch32_clip_448.laion2b_ft_in12k_in1k\n",
      "  - vit_base_patch32_clip_quickgelu_224.laion400m_e32\n",
      "  - vit_base_patch32_clip_quickgelu_224.metaclip_2pt5b\n",
      "  - vit_base_patch32_clip_quickgelu_224.metaclip_400m\n",
      "  - vit_base_patch32_clip_quickgelu_224.openai\n",
      "  - vit_base_patch32_siglip_256.v2_webli\n",
      "  - vit_base_patch32_siglip_gap_256.v2_webli\n",
      "  - vit_base_r50_s16_224.orig_in21k\n",
      "  - vit_base_r50_s16_384.orig_in21k_ft_in1k\n",
      "  - vit_betwixt_patch16_reg1_gap_256.sbb_in1k\n",
      "  - vit_betwixt_patch16_reg4_gap_256.sbb2_e200_in12k\n",
      "  - vit_betwixt_patch16_reg4_gap_256.sbb2_e200_in12k_ft_in1k\n",
      "  - vit_betwixt_patch16_reg4_gap_256.sbb_in1k\n",
      "  - vit_betwixt_patch16_reg4_gap_256.sbb_in12k\n",
      "  - vit_betwixt_patch16_reg4_gap_256.sbb_in12k_ft_in1k\n",
      "  - vit_betwixt_patch16_reg4_gap_384.sbb2_e200_in12k_ft_in1k\n",
      "  - vit_betwixt_patch16_rope_reg4_gap_256.sbb_in1k\n",
      "  - vit_betwixt_patch32_clip_224.tinyclip_laion400m\n",
      "  - vit_giant_patch14_clip_224.laion2b\n",
      "  - vit_giant_patch14_dinov2.lvd142m\n",
      "  - vit_giant_patch14_reg4_dinov2.lvd142m\n",
      "  - vit_giant_patch16_gap_224.in22k_ijepa\n",
      "  - vit_giantopt_patch16_siglip_256.v2_webli\n",
      "  - vit_giantopt_patch16_siglip_384.v2_webli\n",
      "  - vit_giantopt_patch16_siglip_gap_256.v2_webli\n",
      "  - vit_giantopt_patch16_siglip_gap_384.v2_webli\n",
      "  - vit_gigantic_patch14_clip_224.laion2b\n",
      "  - vit_gigantic_patch14_clip_224.metaclip_2pt5b\n",
      "  - vit_gigantic_patch14_clip_quickgelu_224.metaclip_2pt5b\n",
      "  - vit_huge_patch14_224.mae\n",
      "  - vit_huge_patch14_224.orig_in21k\n",
      "  - vit_huge_patch14_clip_224.dfn5b\n",
      "  - vit_huge_patch14_clip_224.laion2b\n",
      "  - vit_huge_patch14_clip_224.laion2b_ft_in1k\n",
      "  - vit_huge_patch14_clip_224.laion2b_ft_in12k\n",
      "  - vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k\n",
      "  - vit_huge_patch14_clip_224.metaclip_2pt5b\n",
      "  - vit_huge_patch14_clip_224.metaclip_altogether\n",
      "  - vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k\n",
      "  - vit_huge_patch14_clip_378.dfn5b\n",
      "  - vit_huge_patch14_clip_quickgelu_224.dfn5b\n",
      "  - vit_huge_patch14_clip_quickgelu_224.metaclip_2pt5b\n",
      "  - vit_huge_patch14_clip_quickgelu_378.dfn5b\n",
      "  - vit_huge_patch14_gap_224.in1k_ijepa\n",
      "  - vit_huge_patch14_gap_224.in22k_ijepa\n",
      "  - vit_huge_patch16_gap_448.in1k_ijepa\n",
      "  - vit_intern300m_patch14_448.ogvl_2pt5\n",
      "  - vit_intern300m_patch14_448.ogvl_dist\n",
      "  - vit_large_patch14_clip_224.datacompxl\n",
      "  - vit_large_patch14_clip_224.dfn2b\n",
      "  - vit_large_patch14_clip_224.dfn2b_s39b\n",
      "  - vit_large_patch14_clip_224.laion2b\n",
      "  - vit_large_patch14_clip_224.laion2b_ft_in1k\n",
      "  - vit_large_patch14_clip_224.laion2b_ft_in12k\n",
      "  - vit_large_patch14_clip_224.laion2b_ft_in12k_in1k\n",
      "  - vit_large_patch14_clip_224.laion400m_e32\n",
      "  - vit_large_patch14_clip_224.metaclip_2pt5b\n",
      "  - vit_large_patch14_clip_224.metaclip_400m\n",
      "  - vit_large_patch14_clip_224.openai\n",
      "  - vit_large_patch14_clip_224.openai_ft_in1k\n",
      "  - vit_large_patch14_clip_224.openai_ft_in12k\n",
      "  - vit_large_patch14_clip_224.openai_ft_in12k_in1k\n",
      "  - vit_large_patch14_clip_336.laion2b_ft_in1k\n",
      "  - vit_large_patch14_clip_336.laion2b_ft_in12k_in1k\n",
      "  - vit_large_patch14_clip_336.openai\n",
      "  - vit_large_patch14_clip_336.openai_ft_in12k_in1k\n",
      "  - vit_large_patch14_clip_quickgelu_224.dfn2b\n",
      "  - vit_large_patch14_clip_quickgelu_224.metaclip_2pt5b\n",
      "  - vit_large_patch14_clip_quickgelu_224.metaclip_400m\n",
      "  - vit_large_patch14_clip_quickgelu_224.openai\n",
      "  - vit_large_patch14_clip_quickgelu_336.openai\n",
      "  - vit_large_patch14_dinov2.lvd142m\n",
      "  - vit_large_patch14_reg4_dinov2.lvd142m\n",
      "  - vit_large_patch16_224.augreg_in21k\n",
      "  - vit_large_patch16_224.augreg_in21k_ft_in1k\n",
      "  - vit_large_patch16_224.mae\n",
      "  - vit_large_patch16_224.orig_in21k\n",
      "  - vit_large_patch16_384.augreg_in21k_ft_in1k\n",
      "  - vit_large_patch16_siglip_256.v2_webli\n",
      "  - vit_large_patch16_siglip_256.webli\n",
      "  - vit_large_patch16_siglip_384.v2_webli\n",
      "  - vit_large_patch16_siglip_384.webli\n",
      "  - vit_large_patch16_siglip_512.v2_webli\n",
      "  - vit_large_patch16_siglip_gap_256.v2_webli\n",
      "  - vit_large_patch16_siglip_gap_256.webli\n",
      "  - vit_large_patch16_siglip_gap_384.v2_webli\n",
      "  - vit_large_patch16_siglip_gap_384.webli\n",
      "  - vit_large_patch16_siglip_gap_512.v2_webli\n",
      "  - vit_large_patch32_224.orig_in21k\n",
      "  - vit_large_patch32_384.orig_in21k_ft_in1k\n",
      "  - vit_large_r50_s32_224.augreg_in21k\n",
      "  - vit_large_r50_s32_224.augreg_in21k_ft_in1k\n",
      "  - vit_large_r50_s32_384.augreg_in21k_ft_in1k\n",
      "  - vit_little_patch16_reg1_gap_256.sbb_in12k\n",
      "  - vit_little_patch16_reg1_gap_256.sbb_in12k_ft_in1k\n",
      "  - vit_little_patch16_reg4_gap_256.sbb_in1k\n",
      "  - vit_medium_patch16_clip_224.tinyclip_yfcc15m\n",
      "  - vit_medium_patch16_gap_240.sw_in12k\n",
      "  - vit_medium_patch16_gap_256.sw_in12k_ft_in1k\n",
      "  - vit_medium_patch16_gap_384.sw_in12k_ft_in1k\n",
      "  - vit_medium_patch16_reg1_gap_256.sbb_in1k\n",
      "  - vit_medium_patch16_reg4_gap_256.sbb_in1k\n",
      "  - vit_medium_patch16_reg4_gap_256.sbb_in12k\n",
      "  - vit_medium_patch16_reg4_gap_256.sbb_in12k_ft_in1k\n",
      "  - vit_medium_patch16_rope_reg1_gap_256.sbb_in1k\n",
      "  - vit_medium_patch32_clip_224.tinyclip_laion400m\n",
      "  - vit_mediumd_patch16_reg4_gap_256.sbb2_e200_in12k\n",
      "  - vit_mediumd_patch16_reg4_gap_256.sbb2_e200_in12k_ft_in1k\n",
      "  - vit_mediumd_patch16_reg4_gap_256.sbb_in12k\n",
      "  - vit_mediumd_patch16_reg4_gap_256.sbb_in12k_ft_in1k\n",
      "  - vit_mediumd_patch16_reg4_gap_384.sbb2_e200_in12k_ft_in1k\n",
      "  - vit_mediumd_patch16_rope_reg1_gap_256.sbb_in1k\n",
      "  - vit_pwee_patch16_reg1_gap_256.sbb_in1k\n",
      "  - vit_relpos_base_patch16_224.sw_in1k\n",
      "  - vit_relpos_base_patch16_clsgap_224.sw_in1k\n",
      "  - vit_relpos_base_patch32_plus_rpn_256.sw_in1k\n",
      "  - vit_relpos_medium_patch16_224.sw_in1k\n",
      "  - vit_relpos_medium_patch16_cls_224.sw_in1k\n",
      "  - vit_relpos_medium_patch16_rpn_224.sw_in1k\n",
      "  - vit_relpos_small_patch16_224.sw_in1k\n",
      "  - vit_small_patch8_224.dino\n",
      "  - vit_small_patch14_dinov2.lvd142m\n",
      "  - vit_small_patch14_reg4_dinov2.lvd142m\n",
      "  - vit_small_patch16_224.augreg_in1k\n",
      "  - vit_small_patch16_224.augreg_in21k\n",
      "  - vit_small_patch16_224.augreg_in21k_ft_in1k\n",
      "  - vit_small_patch16_224.dino\n",
      "  - vit_small_patch16_384.augreg_in1k\n",
      "  - vit_small_patch16_384.augreg_in21k_ft_in1k\n",
      "  - vit_small_patch32_224.augreg_in21k\n",
      "  - vit_small_patch32_224.augreg_in21k_ft_in1k\n",
      "  - vit_small_patch32_384.augreg_in21k_ft_in1k\n",
      "  - vit_small_r26_s32_224.augreg_in21k\n",
      "  - vit_small_r26_s32_224.augreg_in21k_ft_in1k\n",
      "  - vit_small_r26_s32_384.augreg_in21k_ft_in1k\n",
      "  - vit_so150m2_patch16_reg1_gap_256.sbb_e200_in12k\n",
      "  - vit_so150m2_patch16_reg1_gap_256.sbb_e200_in12k_ft_in1k\n",
      "  - vit_so150m2_patch16_reg1_gap_384.sbb_e200_in12k_ft_in1k\n",
      "  - vit_so150m2_patch16_reg1_gap_448.sbb_e200_in12k_ft_in1k\n",
      "  - vit_so150m_patch16_reg4_gap_256.sbb_e250_in12k\n",
      "  - vit_so150m_patch16_reg4_gap_256.sbb_e250_in12k_ft_in1k\n",
      "  - vit_so150m_patch16_reg4_gap_384.sbb_e250_in12k_ft_in1k\n",
      "  - vit_so400m_patch14_siglip_224.v2_webli\n",
      "  - vit_so400m_patch14_siglip_224.webli\n",
      "  - vit_so400m_patch14_siglip_378.v2_webli\n",
      "  - vit_so400m_patch14_siglip_378.webli\n",
      "  - vit_so400m_patch14_siglip_378.webli_ft_in1k\n",
      "  - vit_so400m_patch14_siglip_384.webli\n",
      "  - vit_so400m_patch14_siglip_gap_224.pali2_3b_pt\n",
      "  - vit_so400m_patch14_siglip_gap_224.pali2_10b_pt\n",
      "  - vit_so400m_patch14_siglip_gap_224.pali_mix\n",
      "  - vit_so400m_patch14_siglip_gap_224.pali_pt\n",
      "  - vit_so400m_patch14_siglip_gap_224.v2_webli\n",
      "  - vit_so400m_patch14_siglip_gap_224.webli\n",
      "  - vit_so400m_patch14_siglip_gap_378.v2_webli\n",
      "  - vit_so400m_patch14_siglip_gap_378.webli\n",
      "  - vit_so400m_patch14_siglip_gap_378.webli_ft_in1k\n",
      "  - vit_so400m_patch14_siglip_gap_384.webli\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali2_3b_docci\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali2_3b_pt\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali2_10b_docci\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali2_10b_pt\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali_mix\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali_ocrvqa\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali_pt\n",
      "  - vit_so400m_patch14_siglip_gap_448.pali_refcoco_seg\n",
      "  - vit_so400m_patch14_siglip_gap_896.pali2_3b_pt\n",
      "  - vit_so400m_patch14_siglip_gap_896.pali2_10b_pt\n",
      "  - vit_so400m_patch14_siglip_gap_896.pali_ocrvqa\n",
      "  - vit_so400m_patch14_siglip_gap_896.pali_pt\n",
      "  - vit_so400m_patch14_siglip_gap_896.pali_refcoco_seg\n",
      "  - vit_so400m_patch16_siglip_256.v2_webli\n",
      "  - vit_so400m_patch16_siglip_256.webli_i18n\n",
      "  - vit_so400m_patch16_siglip_384.v2_webli\n",
      "  - vit_so400m_patch16_siglip_512.v2_webli\n",
      "  - vit_so400m_patch16_siglip_gap_256.v2_webli\n",
      "  - vit_so400m_patch16_siglip_gap_256.webli_i18n\n",
      "  - vit_so400m_patch16_siglip_gap_384.v2_webli\n",
      "  - vit_so400m_patch16_siglip_gap_512.v2_webli\n",
      "  - vit_srelpos_medium_patch16_224.sw_in1k\n",
      "  - vit_srelpos_small_patch16_224.sw_in1k\n",
      "  - vit_tiny_patch16_224.augreg_in21k\n",
      "  - vit_tiny_patch16_224.augreg_in21k_ft_in1k\n",
      "  - vit_tiny_patch16_384.augreg_in21k_ft_in1k\n",
      "  - vit_tiny_r_s16_p8_224.augreg_in21k\n",
      "  - vit_tiny_r_s16_p8_224.augreg_in21k_ft_in1k\n",
      "  - vit_tiny_r_s16_p8_384.augreg_in21k_ft_in1k\n",
      "  - vit_wee_patch16_reg1_gap_256.sbb_in1k\n",
      "  - vit_xsmall_patch16_clip_224.tinyclip_yfcc15m\n",
      "  - vitamin_base_224.datacomp1b_clip\n",
      "  - vitamin_base_224.datacomp1b_clip_ltt\n",
      "  - vitamin_large2_224.datacomp1b_clip\n",
      "  - vitamin_large2_256.datacomp1b_clip\n",
      "  - vitamin_large2_336.datacomp1b_clip\n",
      "  - vitamin_large2_384.datacomp1b_clip\n",
      "  - vitamin_large_224.datacomp1b_clip\n",
      "  - vitamin_large_256.datacomp1b_clip\n",
      "  - vitamin_large_336.datacomp1b_clip\n",
      "  - vitamin_large_384.datacomp1b_clip\n",
      "  - vitamin_small_224.datacomp1b_clip\n",
      "  - vitamin_small_224.datacomp1b_clip_ltt\n",
      "  - vitamin_xlarge_256.datacomp1b_clip\n",
      "  - vitamin_xlarge_336.datacomp1b_clip\n",
      "  - vitamin_xlarge_384.datacomp1b_clip\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# List all ConvNeXt model names\n",
    "all_models = timm.list_models('vit*')\n",
    "print(\"üîç All ViT models:\")\n",
    "for name in all_models:\n",
    "    print(\"  -\", name)\n",
    "\n",
    "# List only pretrained ConvNeXt models\n",
    "pretrained_models = timm.list_models('vit*', pretrained=True)\n",
    "print(\"\\n‚úÖ Pretrained ConvNeXt models:\")\n",
    "for name in pretrained_models:\n",
    "    print(\"  -\", name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
