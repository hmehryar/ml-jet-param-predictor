{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "from config import get_config\n",
    "from train_utils.gpu_utils import get_device_summary\n",
    "from data.loader import get_dataloaders\n",
    "from models.model import create_model\n",
    "from train_utils.resume import init_resume_state\n",
    "from train_utils.resume import fill_trackers_from_history\n",
    "from train_utils.training_loop import run_training_loop\n",
    "from train_utils.scheduler_utils import create_scheduler\n",
    "from train_utils.training_summary import finalize_training_summary\n",
    "from train_utils.training_summary import print_best_model_summary\n",
    "from train_utils.plot_metrics import plot_train_val_metrics\n",
    "from train_utils.plot_metrics import plot_loss_accuracy\n",
    "from train_utils.plot_metrics import plot_confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Config Path: /home/arsalan/wsu-grid/ml-jet-param-predictor/experiments/exp_mamaba_vit_stack/config/hybrid_mambaout_base_plus_rw_ViT_tiny_patch16_224_bs64_ep1_lr1e-04_ds1008_g500_sched-RLRP.yml\n",
      "[INFO] Detected native Ubuntu host: DS044955\n",
      "[INFO] Using dataset root: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\n",
      "[INFO] Using dataset_size from config: 1008\n",
      "{\n",
      "  \"model_tag\": \"mambaout_base_plus_rw_ViT_tiny_patch16_224_in1k_g500\",\n",
      "  \"backbone\": [\n",
      "    \"mambaout_base_plus_rw\",\n",
      "    \"vit_tiny_patch16_224\"\n",
      "  ],\n",
      "  \"batch_size\": 64,\n",
      "  \"epochs\": 1,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"patience\": 12,\n",
      "  \"input_shape\": [\n",
      "    1,\n",
      "    32,\n",
      "    32\n",
      "  ],\n",
      "  \"global_max\": 121.79151153564453,\n",
      "  \"dataset_root_dir\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\",\n",
      "  \"train_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds1008_g500_train.csv\",\n",
      "  \"val_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds1008_g500_val.csv\",\n",
      "  \"test_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds1008_g500_test.csv\",\n",
      "  \"output_dir\": \"training_output/mambaout_base_plus_rw_ViT_tiny_patch16_224_in1k_g500_bs64_ep1_lr1e-04_ds1008_g500_sched_ReduceLROnPlateau\",\n",
      "  \"group_size\": 500,\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"ReduceLROnPlateau\",\n",
      "    \"mode\": \"max\",\n",
      "    \"factor\": 0.5,\n",
      "    \"patience\": 4,\n",
      "    \"verbose\": true\n",
      "  },\n",
      "  \"dataset_size\": 1008\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# cfg=get_config(config_path=\"config/convnext_fb_in22k_ft_in1k_bs512_ep50_lr1e-04_ds1000.yml\")\n",
    "# cfg=get_config(config_path=\"config/convnext_fb_in1k_bs512_ep50_lr1e-04_ds1000.yml\")\n",
    "# cfg=get_config(config_path=\"config/convnext_gaussian_bs512_ep50_lr1e-04_ds1000.yml\")\n",
    "# cfg=get_config(config_path=\"config/efficientnet_bs512_ep50_lr1e-01_ds1000_sched-RLRP.yml\")\n",
    "# cfg=get_config(config_path=\"config/vit_\" \\\n",
    "# \"bs512_ep50_lr1e-04_ds1000.yml\")\n",
    "# cfg=get_config(config_path=\"config/mambaout_base_plus_rw_bs32_ep50_lr1e-04_ds1000-g1.yml\")\n",
    "# cfg=get_config(config_path=\"config/mambaout_base_plus_rw_bs16_ep50_lr1e-04_ds1008_g500_sched-RLRP.yml\")\n",
    "\n",
    "from experiments.exp_mamaba_vit_stack.models.hybrid_mamba_vit import create_model\n",
    "# cfg=get_config(config_path=\"/home/arsalan/wsu-grid/ml-jet-param-predictor/\" \\\n",
    "# \"experiments/exp_mamaba_vit_stack/config/\" \\\n",
    "# \"hybrid_mambaout_base_plus_rw_ViT_tiny_patch16_224_bs64_ep1_lr1e-04_ds1008_g500_sched-RLRP.yml\")\n",
    "cfg=get_config()\n",
    "print(json.dumps(vars(cfg), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving all outputs to: training_output/mambaout_base_plus_rw_ViT_tiny_patch16_224_in1k_g500_bs64_ep1_lr1e-04_ds1008_g500_sched_ReduceLROnPlateau\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "print(f\"[INFO] Saving all outputs to: {cfg.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NVIDIA-SMI ===\n",
      "Wed Aug  6 19:25:27 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   43C    P5              26W / 220W |    746MiB /  8192MiB |     26%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2302      G   /usr/lib/xorg/Xorg                          370MiB |\n",
      "|    0   N/A  N/A      2476      G   /usr/bin/gnome-shell                         90MiB |\n",
      "|    0   N/A  N/A     24231      G   ...erProcess --variations-seed-version       45MiB |\n",
      "|    0   N/A  N/A     38953      G   ...seed-version=20250805-050045.273000       45MiB |\n",
      "|    0   N/A  N/A     40222      G   /proc/self/exe                              159MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n",
      "[INFO] PyTorch version:       2.5.1\n",
      "[INFO] Using device: cuda\n",
      "[INFO] CUDA available:        True\n",
      "[INFO] CUDA toolkit version:  12.1\n",
      "[INFO] Device count:          1\n",
      "[INFO] Number of CUDA devices: 1\n",
      "  - CUDA:0 â€” NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "device= get_device_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training samples: 806\n",
      "[INFO] Validation samples: 101\n",
      "[INFO] Test samples: 101\n",
      "[INFO] Length of training dataloader: 13\n",
      "[INFO] Length of validation dataloader: 2\n",
      "[INFO] Length of test dataloader: 2\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "train_loader, val_loader, test_loader = get_dataloaders(cfg, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model, optimizer = create_model(cfg.backbone, cfg.input_shape, cfg.learning_rate)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Parallelizing model across {torch.cuda.device_count()} GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "elif torch.cuda.device_count() == 1:\n",
    "    print(\"No parallelization, using single GPU\")\n",
    "elif torch.cuda.device_count() == 0:\n",
    "    print(\"No GPU available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = create_scheduler(optimizer, cfg, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = {\n",
    "    # 'energy_loss_output': nn.BCELoss(),\n",
    "    'energy_loss_output': nn.BCEWithLogitsLoss(),\n",
    "    'alpha_output': nn.CrossEntropyLoss(),\n",
    "    'q0_output': nn.CrossEntropyLoss()\n",
    "}\n",
    "print(f\"[INFO] Loss functions:{criterion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] Init Training Trackers\")\n",
    "train_loss_energy_list, train_loss_alpha_list, train_loss_q0_list, train_loss_list = [], [], [],[]\n",
    "train_acc_energy_list, train_acc_alpha_list, train_acc_q0_list, train_acc_list = [], [], [], []\n",
    "\n",
    "print(f\"[INFO] Init Validation Trackers\")\n",
    "val_loss_energy_list, val_loss_alpha_list,val_loss_q0_list,val_loss_list = [], [], [], []\n",
    "val_acc_energy_list, val_acc_alpha_list,val_acc_q0_list ,val_acc_list = [],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, start_epoch, best_acc, early_stop_counter, best_epoch, best_metrics, training_summary, all_epoch_metrics,summary_status = init_resume_state( model, optimizer, device,cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_trackers_from_history(\n",
    "    all_epoch_metrics,\n",
    "    train_loss_energy_list, train_loss_alpha_list, train_loss_q0_list, train_loss_list,\n",
    "    train_acc_energy_list, train_acc_alpha_list, train_acc_q0_list, train_acc_list,\n",
    "    val_loss_energy_list, val_loss_alpha_list, val_loss_q0_list, val_loss_list,\n",
    "    val_acc_energy_list, val_acc_alpha_list, val_acc_q0_list, val_acc_list,\n",
    "    summary_status, best_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# train_metrics = train_one_epoch(train_loader, model, criterion, optimizer, device)\n",
    "# print(f\"[INFO] Training metrics: {train_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch,best_acc,best_metrics=run_training_loop(\n",
    "                      cfg,train_loader,val_loader,\n",
    "                      device, model,criterion,\n",
    "                      optimizer,scheduler,\n",
    "                      start_epoch,early_stop_counter,\n",
    "                      best_acc,best_metrics,best_epoch,\n",
    "                      train_loss_list,\n",
    "                        train_loss_energy_list,\n",
    "                        train_loss_alpha_list,\n",
    "                        train_loss_q0_list,\n",
    "                        train_acc_list,\n",
    "                        train_acc_energy_list,\n",
    "                        train_acc_alpha_list,\n",
    "                        train_acc_q0_list,\n",
    "                        val_loss_list,\n",
    "                        val_loss_energy_list,\n",
    "                        val_loss_alpha_list,\n",
    "                        val_loss_q0_list,\n",
    "                        val_acc_list,\n",
    "                        val_acc_energy_list,\n",
    "                        val_acc_alpha_list,\n",
    "                        val_acc_q0_list,\n",
    "                        all_epoch_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize_training_summary(\n",
    "    summary=training_summary,\n",
    "    best_epoch=best_epoch,\n",
    "    best_acc=best_acc,\n",
    "    best_metrics=best_metrics,\n",
    "    output_dir=cfg.output_dir\n",
    ")\n",
    "print_best_model_summary(\n",
    "    best_epoch=best_epoch,\n",
    "    best_acc=best_acc,\n",
    "    best_metrics=best_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_metrics(train_loss_list, val_loss_list, train_acc_list, val_acc_list, cfg.output_dir)\n",
    "plot_loss_accuracy(train_loss_list,\n",
    "                    train_loss_energy_list,\n",
    "                    train_loss_alpha_list,\n",
    "                    train_loss_q0_list,\n",
    "                    train_acc_list,\n",
    "                    train_acc_energy_list,\n",
    "                    train_acc_alpha_list,\n",
    "                    train_acc_q0_list,\n",
    "                    cfg.output_dir,\n",
    "                    title=\"Train Loss and Accuracy per Epoch\")\n",
    "plot_loss_accuracy(val_loss_list,\n",
    "                    val_loss_energy_list,\n",
    "                    val_loss_alpha_list,\n",
    "                    val_loss_q0_list,\n",
    "                    val_acc_list,\n",
    "                    val_acc_energy_list,\n",
    "                    val_acc_alpha_list,\n",
    "                    val_acc_q0_list,\n",
    "                    cfg.output_dir,\n",
    "                    title=\"Validation Loss and Accuracy per Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(best_metrics, output_dir=cfg.output_dir, color_map=\"Oranges\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
