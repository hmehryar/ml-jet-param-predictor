{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /home/arsalan/wsu-grid/ml-jet-param-predictor\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Get the absolute path of the parent folder (where config.py lives)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "print(\"Added to sys.path:\", parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "from config import get_config\n",
    "from train_utils.gpu_utils import get_device_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FLOPs / Params utilities =====\n",
    "# Drop this in a cell after you've created the model\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def _make_dummy_input(input_shape, device):\n",
    "    # input_shape: (C, H, W)\n",
    "    return torch.randn(1, *input_shape, device=device)\n",
    "\n",
    "def count_trainable_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def profile_with_fvcore(model, input_shape, device):\n",
    "    try:\n",
    "        from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    model_eval = model.eval()\n",
    "    dummy = _make_dummy_input(input_shape, device)\n",
    "    with torch.no_grad():\n",
    "        flops = FlopCountAnalysis(model_eval, dummy).total()        # FLOPs (float ops)\n",
    "    params = parameter_count(model_eval)[\"\"]\n",
    "    macs = flops / 2.0                                              # approx: 1 MAC ≈ 2 FLOPs\n",
    "    return dict(params=params, macs=macs, flops=flops)\n",
    "\n",
    "def profile_with_ptflops(model, input_shape, device):\n",
    "    try:\n",
    "        from ptflops import get_model_complexity_info\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    C, H, W = input_shape\n",
    "    # ptflops expects (C, H, W) and returns MACs\n",
    "    model_eval = model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        macs_str, params_str = get_model_complexity_info(\n",
    "            model_eval, (C, H, W), as_strings=True, print_per_layer_stat=False, verbose=False\n",
    "        )\n",
    "    # Parse strings like '12.34 M', '0.56 G'\n",
    "    def _to_num(s):\n",
    "        s = s.strip().upper().replace(' ', '')\n",
    "        if s.endswith('K'): return float(s[:-1]) * 1e3\n",
    "        if s.endswith('M'): return float(s[:-1]) * 1e6\n",
    "        if s.endswith('G'): return float(s[:-1]) * 1e9\n",
    "        return float(s)\n",
    "    macs = _to_num(macs_str)\n",
    "    params = _to_num(params_str)\n",
    "    flops = macs * 2.0  # common convention\n",
    "    return dict(params=params, macs=macs, flops=flops)\n",
    "\n",
    "def profile_model(model, input_shape=(1,32,32), device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Returns a dict with:\n",
    "      - params (int)\n",
    "      - macs   (float, operations)\n",
    "      - flops  (float, operations)\n",
    "      - pretty strings for Params (M), MACs (G), FLOPs (G)\n",
    "    \"\"\"\n",
    "    model = model.to(device).eval()\n",
    "    # First: fvcore (FLOPs), else: ptflops (MACs)\n",
    "    result = profile_with_fvcore(model, input_shape, device)\n",
    "    if result is None:\n",
    "        result = profile_with_ptflops(model, input_shape, device)\n",
    "    if result is None:\n",
    "        raise RuntimeError(\"Neither fvcore nor ptflops is available. Install one of them to compute FLOPs/MACs.\")\n",
    "\n",
    "    params = int(result[\"params\"])\n",
    "    macs   = float(result[\"macs\"])\n",
    "    flops  = float(result[\"flops\"])\n",
    "\n",
    "    pretty = {\n",
    "        \"Params (M)\": f\"{params/1e6:.2f}\",\n",
    "        \"MACs (G)\" : f\"{macs/1e9:.3f}\",\n",
    "        \"FLOPs (G)\": f\"{flops/1e9:.3f}\",\n",
    "    }\n",
    "    return {\"params\": params, \"macs\": macs, \"flops\": flops, \"pretty\": pretty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Example usage after you build your model =====\n",
    "def print_model_profile(model, cfg, device):\n",
    "    try:\n",
    "        trainable_params=count_trainable_params(model)\n",
    "        total_params=sum(p.numel() for p in model.parameters())\n",
    "        prof = profile_model(model, input_shape=cfg.input_shape, device=device)\n",
    "        print(\"Trainable parameters:\", f\"{trainable_params:,}\")\n",
    "        print(\"All parameters:\", f\"{total_params:,}\")\n",
    "        print(\"== Model profile ==\")\n",
    "        for k, v in prof[\"pretty\"].items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        print(\"\\nQuick install (choose one):\")\n",
    "        print(\"  !pip install fvcore\")\n",
    "        print(\"  # or\")\n",
    "        print(\"  !pip install ptflops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NVIDIA-SMI ===\n",
      "Tue Sep  9 12:06:18 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   55C    P5              27W / 220W |    681MiB /  8192MiB |     35%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      3129      G   /usr/lib/xorg/Xorg                          303MiB |\n",
      "|    0   N/A  N/A      3349      G   /usr/bin/gnome-shell                         63MiB |\n",
      "|    0   N/A  N/A      4164      G   /usr/libexec/xdg-desktop-portal-gnome        39MiB |\n",
      "|    0   N/A  N/A     20018      G   /snap/slack/212/usr/lib/slack/slack          84MiB |\n",
      "|    0   N/A  N/A    136883      G   ...seed-version=20250905-050036.934000       44MiB |\n",
      "|    0   N/A  N/A    165485      G   /proc/self/exe                              128MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n",
      "[INFO] PyTorch version:       2.5.1\n",
      "[INFO] Using device: cuda\n",
      "[INFO] CUDA available:        True\n",
      "[INFO] CUDA toolkit version:  12.1\n",
      "[INFO] Device count:          1\n",
      "[INFO] Number of CUDA devices: 1\n",
      "  - CUDA:0 — NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "device= get_device_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Config Path: /home/arsalan/wsu-grid/ml-jet-param-predictor/config/convnext_gaussian_bs32_ep50_lr1e-04_ds7200000_g500_sched-RLRP.yml\n",
      "[INFO] Detected native Ubuntu host: DS044955\n",
      "[INFO] Using dataset root: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\n",
      "[INFO] Extracted dataset_size from path: 7200000\n",
      "{\n",
      "  \"model_tag\": \"ConvNeXt_Gaussian_g500\",\n",
      "  \"backbone\": \"convnext_gaussian\",\n",
      "  \"batch_size\": 32,\n",
      "  \"epochs\": 50,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"patience\": 12,\n",
      "  \"input_shape\": [\n",
      "    1,\n",
      "    32,\n",
      "    32\n",
      "  ],\n",
      "  \"global_max\": 121.79151153564453,\n",
      "  \"dataset_root_dir\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\",\n",
      "  \"train_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_train.csv\",\n",
      "  \"val_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_val.csv\",\n",
      "  \"test_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_test.csv\",\n",
      "  \"output_dir\": \"training_output/ConvNeXt_Gaussian_g500_bs32_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau\",\n",
      "  \"group_size\": 500,\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"ReduceLROnPlateau\",\n",
      "    \"mode\": \"max\",\n",
      "    \"factor\": 0.5,\n",
      "    \"patience\": 4,\n",
      "    \"verbose\": true\n",
      "  },\n",
      "  \"dataset_size\": \"7200000\",\n",
      "  \"preload_model_path\": null,\n",
      "  \"loss_weights\": {\n",
      "    \"energy_loss_output\": 1.0,\n",
      "    \"alpha_output\": 1.0,\n",
      "    \"q0_output\": 1.0\n",
      "  }\n",
      "}\n",
      "[INFO] Saving all outputs to: training_output/ConvNeXt_Gaussian_g500_bs32_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau\n",
      "Using model: convnext_tiny, pretrained: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::gelu encountered 18 time(s)\n",
      "Unsupported operator aten::mul encountered 18 time(s)\n",
      "Unsupported operator aten::add encountered 18 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 27,826,280\n",
      "All parameters: 27,826,280\n",
      "== Model profile ==\n",
      "Params (M): 27.83\n",
      "MACs (G): 0.046\n",
      "FLOPs (G): 0.091\n"
     ]
    }
   ],
   "source": [
    "from models.model import create_model\n",
    "cfg=get_config(config_path=\"/home/arsalan/wsu-grid/ml-jet-param-predictor/config/convnext_gaussian_bs32_ep50_lr1e-04_ds7200000_g500_sched-RLRP.yml\")\n",
    "\n",
    "print(json.dumps(vars(cfg), indent=2))\n",
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "print(f\"[INFO] Saving all outputs to: {cfg.output_dir}\")\n",
    "\n",
    "# Model and optimizer\n",
    "model, optimizer = create_model(cfg.backbone, cfg.input_shape, cfg.learning_rate)\n",
    "model.to(device)\n",
    "print_model_profile(model, cfg, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Config Path: /home/arsalan/wsu-grid/ml-jet-param-predictor/config/efficientnet_bs32_ep50_lr1e-02_ds7200000_g500.yml\n",
      "[INFO] Detected native Ubuntu host: DS044955\n",
      "[INFO] Using dataset root: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\n",
      "[INFO] Extracted dataset_size from path: 7200000\n",
      "{\n",
      "  \"model_tag\": \"EfficientNet_g500\",\n",
      "  \"backbone\": \"efficientnet\",\n",
      "  \"batch_size\": 32,\n",
      "  \"epochs\": 50,\n",
      "  \"learning_rate\": 0.01,\n",
      "  \"patience\": 10,\n",
      "  \"input_shape\": [\n",
      "    1,\n",
      "    32,\n",
      "    32\n",
      "  ],\n",
      "  \"global_max\": 121.79151153564453,\n",
      "  \"dataset_root_dir\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\",\n",
      "  \"train_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_train.csv\",\n",
      "  \"val_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_val.csv\",\n",
      "  \"test_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_test.csv\",\n",
      "  \"output_dir\": \"training_output/EfficientNet_g500_bs32_ep50_lr1e-02_ds7200000_g500_sched_ReduceLROnPlateau\",\n",
      "  \"group_size\": 500,\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"ReduceLROnPlateau\",\n",
      "    \"mode\": \"max\",\n",
      "    \"factor\": 0.5,\n",
      "    \"patience\": 4,\n",
      "    \"verbose\": true\n",
      "  },\n",
      "  \"dataset_size\": \"7200000\",\n",
      "  \"preload_model_path\": null,\n",
      "  \"loss_weights\": {\n",
      "    \"energy_loss_output\": 1.0,\n",
      "    \"alpha_output\": 1.0,\n",
      "    \"q0_output\": 1.0\n",
      "  }\n",
      "}\n",
      "[INFO] Saving all outputs to: training_output/EfficientNet_g500_bs32_ep50_lr1e-02_ds7200000_g500_sched_ReduceLROnPlateau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 49 time(s)\n",
      "Unsupported operator aten::mean encountered 16 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 16 time(s)\n",
      "Unsupported operator aten::mul encountered 16 time(s)\n",
      "Unsupported operator aten::add encountered 9 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 4,017,220\n",
      "All parameters: 4,017,220\n",
      "== Model profile ==\n",
      "Params (M): 4.02\n",
      "MACs (G): 0.004\n",
      "FLOPs (G): 0.009\n"
     ]
    }
   ],
   "source": [
    "from models.model import create_model\n",
    "cfg=get_config(config_path=\"/home/arsalan/wsu-grid/ml-jet-param-predictor/config/efficientnet_bs32_ep50_lr1e-02_ds7200000_g500.yml\")\n",
    "\n",
    "print(json.dumps(vars(cfg), indent=2))\n",
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "print(f\"[INFO] Saving all outputs to: {cfg.output_dir}\")\n",
    "\n",
    "# Model and optimizer\n",
    "model, optimizer = create_model(cfg.backbone, cfg.input_shape, cfg.learning_rate)\n",
    "model.to(device)\n",
    "print_model_profile(model, cfg, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Config Path: /home/arsalan/wsu-grid/ml-jet-param-predictor/config/swin_bs32_ep50_lr1e-04_ds7200000_g500.yml\n",
      "[INFO] Detected native Ubuntu host: DS044955\n",
      "[INFO] Using dataset root: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\n",
      "[INFO] Extracted dataset_size from path: 7200000\n",
      "{\n",
      "  \"model_tag\": \"Swin_g500\",\n",
      "  \"backbone\": \"swin\",\n",
      "  \"batch_size\": 32,\n",
      "  \"epochs\": 50,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"patience\": 10,\n",
      "  \"input_shape\": [\n",
      "    1,\n",
      "    32,\n",
      "    32\n",
      "  ],\n",
      "  \"global_max\": 121.79151153564453,\n",
      "  \"dataset_root_dir\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\",\n",
      "  \"train_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_train.csv\",\n",
      "  \"val_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_val.csv\",\n",
      "  \"test_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_test.csv\",\n",
      "  \"output_dir\": \"training_output/Swin_g500_bs32_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau\",\n",
      "  \"group_size\": 500,\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"ReduceLROnPlateau\",\n",
      "    \"mode\": \"max\",\n",
      "    \"factor\": 0.5,\n",
      "    \"patience\": 4,\n",
      "    \"verbose\": true\n",
      "  },\n",
      "  \"dataset_size\": \"7200000\",\n",
      "  \"preload_model_path\": null,\n",
      "  \"loss_weights\": {\n",
      "    \"energy_loss_output\": 1.0,\n",
      "    \"alpha_output\": 1.0,\n",
      "    \"q0_output\": 1.0\n",
      "  }\n",
      "}\n",
      "[INFO] Saving all outputs to: training_output/Swin_g500_bs32_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::rsub encountered 24 time(s)\n",
      "Unsupported operator aten::pad encountered 15 time(s)\n",
      "Unsupported operator aten::mul encountered 12 time(s)\n",
      "Unsupported operator aten::add encountered 37 time(s)\n",
      "Unsupported operator aten::softmax encountered 12 time(s)\n",
      "Unsupported operator aten::gelu encountered 12 time(s)\n",
      "Unsupported operator aten::mean encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "backbone.layers.0.blocks.1.drop_path1, backbone.layers.0.blocks.1.drop_path2, backbone.layers.1.blocks.0.drop_path1, backbone.layers.1.blocks.0.drop_path2, backbone.layers.1.blocks.1.drop_path1, backbone.layers.1.blocks.1.drop_path2, backbone.layers.2.blocks.0.drop_path1, backbone.layers.2.blocks.0.drop_path2, backbone.layers.2.blocks.1.drop_path1, backbone.layers.2.blocks.1.drop_path2, backbone.layers.2.blocks.2.drop_path1, backbone.layers.2.blocks.2.drop_path2, backbone.layers.2.blocks.3.drop_path1, backbone.layers.2.blocks.3.drop_path2, backbone.layers.2.blocks.4.drop_path1, backbone.layers.2.blocks.4.drop_path2, backbone.layers.2.blocks.5.drop_path1, backbone.layers.2.blocks.5.drop_path2, backbone.layers.3.blocks.0.drop_path1, backbone.layers.3.blocks.0.drop_path2, backbone.layers.3.blocks.1.drop_path1, backbone.layers.3.blocks.1.drop_path2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 27,500,690\n",
      "All parameters: 27,500,690\n",
      "== Model profile ==\n",
      "Params (M): 27.50\n",
      "MACs (G): 0.045\n",
      "FLOPs (G): 0.090\n"
     ]
    }
   ],
   "source": [
    "from models.model import create_model\n",
    "cfg=get_config(config_path=\"/home/arsalan/wsu-grid/ml-jet-param-predictor/config/swin_bs32_ep50_lr1e-04_ds7200000_g500.yml\")\n",
    "\n",
    "print(json.dumps(vars(cfg), indent=2))\n",
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "print(f\"[INFO] Saving all outputs to: {cfg.output_dir}\")\n",
    "\n",
    "# Model and optimizer\n",
    "model, optimizer = create_model(cfg.backbone, cfg.input_shape, cfg.learning_rate)\n",
    "model.to(device)\n",
    "print_model_profile(model, cfg, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 25 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 12 time(s)\n",
      "Unsupported operator aten::gelu encountered 12 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "backbone.blocks.0.attn.attn_drop, backbone.blocks.1.attn.attn_drop, backbone.blocks.10.attn.attn_drop, backbone.blocks.11.attn.attn_drop, backbone.blocks.2.attn.attn_drop, backbone.blocks.3.attn.attn_drop, backbone.blocks.4.attn.attn_drop, backbone.blocks.5.attn.attn_drop, backbone.blocks.6.attn.attn_drop, backbone.blocks.7.attn.attn_drop, backbone.blocks.8.attn.attn_drop, backbone.blocks.9.attn.attn_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Config Path: /home/arsalan/wsu-grid/ml-jet-param-predictor/experiments/exp_preload_trained_model_and_train_more/config/vit_tiny_patch16_224_gaussian_bs32_ep50_lr1e-04_p12_ds7200000_g500_sched-RLRP_preload_p4.yml\n",
      "[INFO] Detected native Ubuntu host: DS044955\n",
      "[INFO] Using dataset root: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\n",
      "[INFO] Using dataset_size from config: 7200000\n",
      "{\n",
      "  \"model_tag\": \"ViT_tiny_patch16_224_gaussian_lrp_12_rlrp_4\",\n",
      "  \"backbone\": \"vit_gaussian\",\n",
      "  \"batch_size\": 32,\n",
      "  \"epochs\": 50,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"patience\": 12,\n",
      "  \"input_shape\": [\n",
      "    1,\n",
      "    32,\n",
      "    32\n",
      "  ],\n",
      "  \"global_max\": 121.79151153564453,\n",
      "  \"dataset_root_dir\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\",\n",
      "  \"train_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_train.csv\",\n",
      "  \"val_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_val.csv\",\n",
      "  \"test_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_test.csv\",\n",
      "  \"output_dir\": \"experiments/exp_preload_trained_model_and_train_more/training_output/ViT_tiny_patch16_224_gaussian_lrp_12_rlrp_4_bs32_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau_preloaded\",\n",
      "  \"group_size\": 500,\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"ReduceLROnPlateau\",\n",
      "    \"mode\": \"max\",\n",
      "    \"factor\": 0.5,\n",
      "    \"patience\": 4,\n",
      "    \"verbose\": true\n",
      "  },\n",
      "  \"dataset_size\": 7200000,\n",
      "  \"preload_model_path\": \"training_output/ViT_tiny_patch16_224_gaussian_g500_bs32_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau/best_model.pth\",\n",
      "  \"loss_weights\": {\n",
      "    \"energy_loss_output\": 1.0,\n",
      "    \"alpha_output\": 1.0,\n",
      "    \"q0_output\": 1.0\n",
      "  }\n",
      "}\n",
      "[INFO] Saving all outputs to: experiments/exp_preload_trained_model_and_train_more/training_output/ViT_tiny_patch16_224_gaussian_lrp_12_rlrp_4_bs32_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau_preloaded\n",
      "Using ViT model: vit_tiny_patch16_224, pretrained: False\n",
      "Trainable parameters: 5,525,960\n",
      "All parameters: 5,525,960\n",
      "== Model profile ==\n",
      "Params (M): 5.53\n",
      "MACs (G): 0.540\n",
      "FLOPs (G): 1.080\n"
     ]
    }
   ],
   "source": [
    "from models.model_vit import create_model\n",
    "cfg=get_config(config_path=\"/home/arsalan/wsu-grid/ml-jet-param-predictor/\" \\\n",
    "\"experiments/exp_preload_trained_model_and_train_more/config/vit_tiny_patch16_224_gaussian_bs32_ep50_lr1e-04_p12_ds7200000_g500_sched-RLRP_preload_p4.yml\")\n",
    "\n",
    "print(json.dumps(vars(cfg), indent=2))\n",
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "print(f\"[INFO] Saving all outputs to: {cfg.output_dir}\")\n",
    "\n",
    "# Model and optimizer\n",
    "model, optimizer = create_model(cfg.backbone, cfg.input_shape, cfg.learning_rate)\n",
    "model.to(device)\n",
    "print_model_profile(model, cfg, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Config Path: /home/arsalan/wsu-grid/ml-jet-param-predictor/experiments/exp_preload_trained_model_and_train_more/config/mambaout_base_plus_rw_bs16_ep50_lr1e-04_p12_ds7200000_g500_sched-RLRP_preload-p4.yml\n",
      "[INFO] Detected native Ubuntu host: DS044955\n",
      "[INFO] Using dataset root: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\n",
      "[INFO] Using dataset_size from config: 7200000\n",
      "{\n",
      "  \"model_tag\": \"MambaOut_base_plus_rw_lrp_12_rlrp_4\",\n",
      "  \"backbone\": \"mambaout_base_plus_rw\",\n",
      "  \"batch_size\": 16,\n",
      "  \"epochs\": 50,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"patience\": 12,\n",
      "  \"input_shape\": [\n",
      "    1,\n",
      "    32,\n",
      "    32\n",
      "  ],\n",
      "  \"global_max\": 121.79151153564453,\n",
      "  \"dataset_root_dir\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled\",\n",
      "  \"train_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_train.csv\",\n",
      "  \"val_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_val.csv\",\n",
      "  \"test_csv\": \"/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_7200000_balanced_unshuffled/file_labels_aggregated_ds7200000_g500_test.csv\",\n",
      "  \"output_dir\": \"experiments/exp_preload_trained_model_and_train_more/training_output/MambaOut_base_plus_rw_lrp_12_rlrp_4_bs16_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau_preloaded\",\n",
      "  \"group_size\": 500,\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"ReduceLROnPlateau\",\n",
      "    \"mode\": \"max\",\n",
      "    \"factor\": 0.5,\n",
      "    \"patience\": 4,\n",
      "    \"verbose\": true\n",
      "  },\n",
      "  \"dataset_size\": 7200000,\n",
      "  \"preload_model_path\": \"training_output/mambaout_base_plus_rw_g500_bs16_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau/best_model.pth\",\n",
      "  \"loss_weights\": {\n",
      "    \"energy_loss_output\": 1.0,\n",
      "    \"alpha_output\": 1.0,\n",
      "    \"q0_output\": 1.0\n",
      "  }\n",
      "}\n",
      "[INFO] Saving all outputs to: experiments/exp_preload_trained_model_and_train_more/training_output/MambaOut_base_plus_rw_lrp_12_rlrp_4_bs16_ep50_lr1e-04_ds7200000_g500_sched_ReduceLROnPlateau_preloaded\n",
      "Using Mamba model: mambaout_base_plus_rw, pretrained: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::silu encountered 41 time(s)\n",
      "Unsupported operator aten::mul encountered 80 time(s)\n",
      "Unsupported operator aten::add encountered 40 time(s)\n",
      "Unsupported operator aten::mean encountered 1 time(s)\n",
      "Unsupported operator aten::gelu encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 98,608,136\n",
      "All parameters: 98,608,136\n",
      "== Model profile ==\n",
      "Params (M): 98.61\n",
      "MACs (G): 9.595\n",
      "FLOPs (G): 19.190\n"
     ]
    }
   ],
   "source": [
    "from models.model_mamba import create_model\n",
    "cfg=get_config(config_path=\"/home/arsalan/wsu-grid/ml-jet-param-predictor/\" \\\n",
    "\"experiments/exp_preload_trained_model_and_train_more/config/mambaout_base_plus_rw_bs16_ep50_lr1e-04_p12_ds7200000_g500_sched-RLRP_preload-p4.yml\")\n",
    "\n",
    "print(json.dumps(vars(cfg), indent=2))\n",
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "print(f\"[INFO] Saving all outputs to: {cfg.output_dir}\")\n",
    "\n",
    "# Model and optimizer\n",
    "model, optimizer = create_model(cfg.backbone, cfg.input_shape, cfg.learning_rate)\n",
    "model.to(device)\n",
    "print_model_profile(model, cfg, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
